{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS17_431_RNN_and_LSTM_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7QXzrvrSjru",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
        "<br></br>\n",
        "<br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_5DZJg0Sjrw",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IizNKWLomoA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
        "\n",
        "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
        "\n",
        "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
        "\n",
        "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fkzy3-FDSjr1"
      },
      "source": [
        "## Overview\n",
        "\n",
        "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
        "\n",
        "$F_n = F_{n-1} + F_{n-2}$\n",
        "\n",
        "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
        "\n",
        "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
        "\n",
        "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
        "\n",
        "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
        "\n",
        "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
        "\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgdZYqBadli6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "897784ff-e3f3-478d-bebd-0ec0775af462"
      },
      "source": [
        "# Vanishing gradients\n",
        "# 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001\n",
        "0.0001 ** 1000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TKrg7cMKSjr8"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ti23G0gRe3kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c0da1a6c-f817-4ffb-ee57-c5dcc92d10b6"
      },
      "source": [
        "'''\n",
        "#Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "**Notes**\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHSOnf3ASjsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dab63b3e-d241-42b9-a237-92c4c3741c1e"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpMv7Ha8iSDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "124cbc1a-7d15-4c29-f5e4-7468d86e2275"
      },
      "source": [
        "# Prep-padding shape\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (25000,)\n",
            "x_test shape:  (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmm5Q6BkiW-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89849c9a-16ef-4040-b128-47a52053fe5f"
      },
      "source": [
        "len(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Uu_xSUibaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a8fedb9-ee36-4dee-bbd0-356fabaf895f"
      },
      "source": [
        "[len(x) for x in x_train[:10]]  # num words in first ten reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[218, 189, 141, 550, 147, 43, 123, 562, 233, 130]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFHhoTSAio7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "1f54372a-273d-4d24-9dc9-3c665e5f1bdf"
      },
      "source": [
        "# 5th review is short\n",
        "x_train[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 778,\n",
              " 128,\n",
              " 74,\n",
              " 12,\n",
              " 630,\n",
              " 163,\n",
              " 15,\n",
              " 4,\n",
              " 1766,\n",
              " 7982,\n",
              " 1051,\n",
              " 2,\n",
              " 32,\n",
              " 85,\n",
              " 156,\n",
              " 45,\n",
              " 40,\n",
              " 148,\n",
              " 139,\n",
              " 121,\n",
              " 664,\n",
              " 665,\n",
              " 10,\n",
              " 10,\n",
              " 1361,\n",
              " 173,\n",
              " 4,\n",
              " 749,\n",
              " 2,\n",
              " 16,\n",
              " 3804,\n",
              " 8,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 12,\n",
              " 43,\n",
              " 127,\n",
              " 24,\n",
              " 15344,\n",
              " 10,\n",
              " 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic0jzRvzSjsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dea1d0ab-fb98-42e2-b6d9-0b5d757a02e6"
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRxQrGTCSjsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a96e850e-8559-428c-c0e3-1a616581da44"
      },
      "source": [
        "x_train[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     1,   778,   128,    74,    12,   630,   163,    15,\n",
              "           4,  1766,  7982,  1051,     2,    32,    85,   156,    45,\n",
              "          40,   148,   139,   121,   664,   665,    10,    10,  1361,\n",
              "         173,     4,   749,     2,    16,  3804,     8,     4,   226,\n",
              "          65,    12,    43,   127,    24, 15344,    10,    10],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOPCEfWki67m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "0ce357ed-3e47-487a-f0bf-3f167e3d1bee"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHDK11zsSjsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "2cf2fc81-251d-444d-d782-a751e58cad0f"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "# https://stackoverflow.com/questions/44924690/keras-the-difference-between-lstm-dropout-and-lstm-recurrent-dropout\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgC8gsgYSjso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "73aa6d25-2a7f-46d2-ac6b-9465c0ed344f"
      },
      "source": [
        "unicorns = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=2, \n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "782/782 [==============================] - 244s 312ms/step - loss: 0.4080 - accuracy: 0.8176 - val_loss: 0.3522 - val_accuracy: 0.8442\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 243s 311ms/step - loss: 0.2513 - accuracy: 0.9000 - val_loss: 0.4247 - val_accuracy: 0.8330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfydL-ZRSjst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6cfc5a17-152e-4b67-e03b-aac33a3792d8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns.history['loss'])\n",
        "plt.plot(unicorns.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY1QYAX5Sjsz",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7pETWPIe362y"
      },
      "source": [
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVFa0NC7Sjs1"
      },
      "source": [
        "## Overview\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-kuJzHnSjs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB2EzxcmmWhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "55720581-9f23-432e-a888-b2f9529734aa"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>The Queens Speech is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  The Queens Speech is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uoj5TAaSjs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "b714f8bc-f6e0-4bc4-a0a4-59e3584f96de"
      },
      "source": [
        "# data_files = os.listdir('./articles')  # If you're running locally"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ac14733210b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./articles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './articles'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10-d1GUVSjtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./articles/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL56kYH_SjtK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbce153b-5076-417b-deda-0fb3be2b4259"
      },
      "source": [
        "data = df['article'].values\n",
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYu5BO-_SjtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "95b1baf5-a820-4f74-a0c2-f1afd33970c3"
      },
      "source": [
        "data[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The threat to hard-won womens rights in Rojava is receiving little coverage in the context of Turkeys military campaign, but women there say Turkish aggression could wipe out these reforms and perhaps herald a return to the misogyny and sexual violence of militant Islamism. There is widespread concern about the possible escape of ISIS prisoners held by Kurdish forces, and on Sunday, it was reported that at least 750 people suspected of affiliation with ISIS fled a secure displacement camp in the chaos caused by Turkish shelling. In addition, several dozen high-value ISIS prisoners were reportedly left behind by U.S. troops when they retreated, the New York Times reported, and ISIS has already claimed at least two attacks in the area since the invasion started, including a car bombing that killed three people.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QPh0KzSjtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJW9phVonGhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ace6002f-67ed-45bf-d577-d16ca6dd7139"
      },
      "source": [
        "char_int['a']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ginZieymnNdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9c11b2cd-6492-4a00-fae1-c20da2265065"
      },
      "source": [
        "int_char[110]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfVb3B2LSjtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "708f4e4a-931d-4859-9ed3-11767dba672e"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DseSknmVSjtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abc6e247-ce32-4e57-b12f-3a06a806d8c1"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  178374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePaAxnVnexK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dce9af5c-bef1-4f98-fc3b-3912ba4a269b"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891910"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve5OyG_zSjth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "11626550-0454-44c4-c785-ca299abb2ed4"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[52,\n",
              " 14,\n",
              " 21,\n",
              " 82,\n",
              " 84,\n",
              " 3,\n",
              " 75,\n",
              " 60,\n",
              " 82,\n",
              " 3,\n",
              " 21,\n",
              " 66,\n",
              " 63,\n",
              " 34,\n",
              " 14,\n",
              " 37,\n",
              " 60,\n",
              " 100,\n",
              " 21,\n",
              " 3,\n",
              " 47,\n",
              " 82,\n",
              " 96,\n",
              " 96,\n",
              " 54,\n",
              " 0,\n",
              " 13,\n",
              " 63,\n",
              " 49,\n",
              " 14,\n",
              " 60,\n",
              " 47,\n",
              " 13,\n",
              " 63,\n",
              " 3,\n",
              " 47,\n",
              " 63,\n",
              " 14,\n",
              " 21,\n",
              " 63]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUoyd1nySjtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "# Padding!\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMBX5AwXSjto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cf7483e-f486-4bc9-8b45-eeae86d34b1e"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 40, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJH4cRcBSjtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48ac9439-e1cf-439c-968b-a2abd2e76bf7"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b91wThegSjtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRH_nrjjoKsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "f9e59b85-86c0-47b4-cfea-0ec246a03103"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               128000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 121)               15609     \n",
            "=================================================================\n",
            "Total params: 143,609\n",
            "Trainable params: 143,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFIHVwXmSjt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xJL0gA0Sjt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    # Random prompt\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        # Predict the next step (character)\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoJKLihxSjt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "823adc0d-b61e-4753-c023-e0bbeca16b34"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5564/5575 [============================>.] - ETA: 0s - loss: 2.5500\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"visitors. (Kiichiro Sato/AP)\n",
            "\n",
            "The log se\"\n",
            "visitors. (Kiichiro Sato/AP)\n",
            "\n",
            "The log seand Cheraydockaw as ad with thet hay trise ofter to inostave.\n",
            "\n",
            "The inde bat the ulrmalte ay as pcodiol.&s:\n",
            "\n",
            "I. Une jeate severice the M0 er arins be sporgans Fonvar Qnwerpoonel lon the ia, of ier yom Yhanc Komion Oed a dat y a spome ander Jasmathop the cokingingo ziny he Binged on that Parmion of ceurca morse thatV arsin the-mwithaw hed the TiUI\n",
            "\n",
            "Lam whoSe naker qowisket.. Aad Salt. As ot rogh\n",
            "5575/5575 [==============================] - 36s 6ms/step - loss: 2.5497\n",
            "Epoch 2/10\n",
            "5572/5575 [============================>.] - ETA: 0s - loss: 2.2045\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"d in a tempered commentary published Mon\"\n",
            "d in a tempered commentary published Mond aides off mendy. Thas, anf 20-oiel andern eve foees.\n",
            "\n",
            "\"sleted) thath oituenal ere contreed frkes Trump hory. The to enaged on poumizirentiins, and and onate they Mreling thas reasest fot com action for Hadd to Wlick.\n",
            "\n",
            "Relordell indedimas in Bporma. Whatlers? Mrinkine Trompld ar a.k net beicledsy to prowin a aidlesset and dote now ahl Propled in thatcesp acrianl indsegned acterity on imponver. \n",
            "5575/5575 [==============================] - 35s 6ms/step - loss: 2.2044\n",
            "Epoch 3/10\n",
            "5571/5575 [============================>.] - ETA: 0s - loss: 2.0751\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"his son Hunter  just barely missed the \"\n",
            "his son Hunter  just barely missed the grinatial ants yon thear And 16, -y cancem no Trum, uriviss to is a Sust ot ht wroter but enditile and an P in is the court, bunlesed in the Fistenn that thacional of the pislias mugr aw the mone from the have agwing, arto. The pists by bro panding with Fom Bentas forg a tave a Imaive Wished) Lled a buin.\n",
            "\n",
            "AD\n",
            "\n",
            "The plase anthed wanth have Wome it brolbo But ToBm3 han Sinfie in whist ik Jrusp ank\n",
            "5575/5575 [==============================] - 35s 6ms/step - loss: 2.0749\n",
            "Epoch 4/10\n",
            "5571/5575 [============================>.] - ETA: 0s - loss: 1.9866\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"in towers were struck by hijacked airpla\"\n",
            "in towers were struck by hijacked airplation and desiditing to youse it lanerge to incertur that cayes it ome impeen to dearsed for was himn.\n",
            "\n",
            "Thelibe : Yougery aty cruasdatee. Itwallsss: (Fproine store parming sightian your enows a compronion rice in the protemestuinds and slioking ugh aveablioters. I have that led beke baturess a reguing tiaral ampitations as thr lest In Wosh, shavery enelages ne reciake. Cillsent it lats, the firgr\n",
            "5575/5575 [==============================] - 35s 6ms/step - loss: 1.9864\n",
            "Epoch 5/10\n",
            "5567/5575 [============================>.] - ETA: 0s - loss: 1.9157\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"at Columbia Heights continues to remain \"\n",
            "at Columbia Heights continues to remain onstille a ois mides to yead 2000 Holicia on you not whith allowmentions a shorle, blonate atother froving they ganspatiesene. The fige. He hove inease ofleched hat was she sworlt the Sexilan and is retormoush.\n",
            "\n",
            "\n",
            "\n",
            " and collins of murith copportor., and previiguect theached. Changenan-of foold amoet the obttennde quested thtys misto.\n",
            "\n",
            "AD\n",
            "\n",
            "There a wom.\n",
            "\n",
            "AD\n",
            "\n",
            "AD\n",
            "\n",
            "Jrodes of Nom Ly Fonszs]\n",
            "\n",
            "Fut is lo\n",
            "5575/5575 [==============================] - 36s 6ms/step - loss: 1.9158\n",
            "Epoch 6/10\n",
            "5566/5575 [============================>.] - ETA: 0s - loss: 1.8578\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"protesters courting arrest from Amsterda\"\n",
            "protesters courting arrest from Amsterday, Ro, long pat sty dalling yrumber Bign Syrian the Senvinated they an remease not the Eurds Amerisan Wasnias on 1015, mut Lampr Oaken, CBYaine  Trumps off monstor Trumps so degring that yough her fourver, acpice to renking of the councy fram haves a has goald the ..\n",
            "\n",
            "Spocker, $5-yows lowss who in appreesussboom telim in usered to than a shordol twere. He played to a shorging the can Out C\n",
            "5575/5575 [==============================] - 35s 6ms/step - loss: 1.8578\n",
            "Epoch 7/10\n",
            "5575/5575 [==============================] - ETA: 0s - loss: 1.8088\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \" David and Goliath and the voice of God.\"\n",
            " David and Goliath and the voice of God.\n",
            "\n",
            "The preducal departs of exerss fo consuenly and beren Rauphing addited of NBtiguss or peryom to she heach from har countrytive lepman for spice use videt Syreas perscripe the was any univarokic and it ferving matus. A DeigO at the videation bock notrecturing ownstank the whother chimgent scordermpory the perfenced paid nge day gancusation & Hliaksh pertods shoit.\n",
            "\n",
            "Syriadd you as a yeage can\n",
            "5575/5575 [==============================] - 36s 6ms/step - loss: 1.8088\n",
            "Epoch 8/10\n",
            "5575/5575 [==============================] - ETA: 0s - loss: 1.7667\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \" sources recommend increasing the oven t\"\n",
            " sources recommend increasing the oven that tack connicies mas secees a forse or Seprates and sear heme whenow? so that presunge of the pates, adgetsiontic about to telin dos winn The Ohe prosists saie would nepped. Lot $1164'thoung 18 teouquy natements in whecher sardent desschause a mideation was be a reaider this stack.\n",
            "\n",
            "Johthan media as 2gare Wash altemenated it the pouse narped they veriticy, dopergess dradoigs comp they arsops. \n",
            "5575/5575 [==============================] - 36s 6ms/step - loss: 1.7667\n",
            "Epoch 9/10\n",
            "5565/5575 [============================>.] - ETA: 0s - loss: 1.7300\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"criminal. What he did is criminal.\"\n",
            "\n",
            "At \"\n",
            "criminal. What he did is criminal.\"\n",
            "\n",
            "At was is new a keactian oveldariogingty that Carras Accrabury to flmetial sparter arr, Rigar aloplipacy subberrerse.\n",
            "\n",
            "AD\n",
            "\n",
            "The promping the seeter withiral the for or dim rile gin tomen shooters and Mrap fursuman take heme alacy said of Schoil Trump that caintival whosel Hot Trump Ukvania Chotem. Af the ison the allotablowing hola shaten fireiee white laker they kid:\n",
            "\n",
            "AD\n",
            "\n",
            "Thors, even making mut We $\n",
            "5575/5575 [==============================] - 35s 6ms/step - loss: 1.7302\n",
            "Epoch 10/10\n",
            "5569/5575 [============================>.] - ETA: 0s - loss: 1.6974\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"e  on the page in his account of the li\"\n",
            "e  on the page in his account of the like, oppearing, whose his pastion poesety expertanies it with toly rocined betarcounaked takes, was support in Americh Mcones in vlith Rossited and experron is world in Sextan actors and denlited to report .m. 4 requither blacks aways houp when feek is norghed: Sackess and tham and recaliticals.\n",
            "\n",
            "Obrough tho Trump his one Cobsta, were ano theesy cunclessions allow has wavernly suffly and apprea\n",
            "5575/5575 [==============================] - 36s 6ms/step - loss: 1.6972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcde6c90908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vh4ElzDSjuB",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rys0_j8CSjuD",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}